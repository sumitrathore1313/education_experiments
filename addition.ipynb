{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## We are going add two numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning\n",
    "    1- convert number into binary and use feed forward network and lstm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num1 = numpy.random.randint(0, 1000, size=1000)\n",
    "num2 = numpy.random.randint(0, 1000, size=1000)\n",
    "ans = num1+num2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = numpy.concatenate((num1.reshape(num1.shape[0], 1), num2.reshape(num2.shape[0], 1), ans.reshape(ans.shape[0], 1)), axis=1)\n",
    "# data_frame = pd.DataFrame(temp, columns=['num1', 'num2', 'ans'])\n",
    "# data_frame.to_csv('data/addition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 0 1 1 1]\n",
      "0b1010100\n",
      "0b1000110111\n",
      "0b1010001011\n"
     ]
    }
   ],
   "source": [
    "temp = []\n",
    "for num in num1:\n",
    "    bin_num = bin(num)[2:]\n",
    "    temp1 = [0 for i in range(12)]\n",
    "    for i in range(len(bin_num)):\n",
    "        temp1[-i-1] = int(bin_num[-i-1])\n",
    "    temp.append(temp1)\n",
    "bin_num1 = temp\n",
    "temp = []\n",
    "for num in num2:\n",
    "    bin_num = bin(num)[2:]\n",
    "    temp1 = [0 for i in range(12)]\n",
    "    for i in range(len(bin_num)):\n",
    "        temp1[-i-1] = int(bin_num[-i-1])\n",
    "    temp.append(temp1)\n",
    "bin_num2 = temp\n",
    "temp = []\n",
    "for num in ans:\n",
    "    bin_num = bin(num)[2:]\n",
    "    temp1 = [0 for i in range(12)]\n",
    "    for i in range(len(bin_num)):\n",
    "        temp1[-i-1] = int(bin_num[-i-1])\n",
    "    temp.append(temp1)\n",
    "train_y = temp\n",
    "train_x =  numpy.concatenate((bin_num1, bin_num2), axis=1)\n",
    "print(train_x[31])\n",
    "print(bin(num1[31]))\n",
    "print(bin(num2[31]))\n",
    "print(bin(ans[31]))\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 1s 596us/step - loss: 13.4362 - acc: 0.1430\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 386us/step - loss: 13.2175 - acc: 0.1550\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 403us/step - loss: 13.1624 - acc: 0.1470\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 394us/step - loss: 13.1395 - acc: 0.1700\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 415us/step - loss: 13.1256 - acc: 0.1370\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 403us/step - loss: 13.1122 - acc: 0.1600\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s 396us/step - loss: 13.1009 - acc: 0.1990\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s 401us/step - loss: 13.0879 - acc: 0.2010\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s 410us/step - loss: 13.0728 - acc: 0.2210\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 432us/step - loss: 13.0569 - acc: 0.2860\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 402us/step - loss: 13.0374 - acc: 0.3120\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 415us/step - loss: 13.0183 - acc: 0.3580\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 396us/step - loss: 12.9990 - acc: 0.3600\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 387us/step - loss: 12.9780 - acc: 0.4000\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 394us/step - loss: 12.9617 - acc: 0.4210\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 399us/step - loss: 12.9455 - acc: 0.4200\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s 407us/step - loss: 12.9313 - acc: 0.4310\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s 404us/step - loss: 12.9188 - acc: 0.4290\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s 457us/step - loss: 12.9084 - acc: 0.4360\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s 459us/step - loss: 12.8977 - acc: 0.4510\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s 497us/step - loss: 12.8878 - acc: 0.4350\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 1s 567us/step - loss: 12.8847 - acc: 0.4580\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 428us/step - loss: 12.8733 - acc: 0.4470\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s 407us/step - loss: 12.8679 - acc: 0.4400\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 429us/step - loss: 12.8582 - acc: 0.4940\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s 420us/step - loss: 12.8518 - acc: 0.4510\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 418us/step - loss: 12.8439 - acc: 0.4550\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 474us/step - loss: 12.8354 - acc: 0.4710\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 416us/step - loss: 12.8306 - acc: 0.4630\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 392us/step - loss: 12.8222 - acc: 0.4720\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 12.8136 - acc: 0.4670\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 449us/step - loss: 12.8089 - acc: 0.4790\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 418us/step - loss: 12.8001 - acc: 0.4820\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 384us/step - loss: 12.7918 - acc: 0.4720\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 393us/step - loss: 12.7830 - acc: 0.4690\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 408us/step - loss: 12.7753 - acc: 0.4660\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 409us/step - loss: 12.7700 - acc: 0.4640\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 425us/step - loss: 12.7569 - acc: 0.4620\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 405us/step - loss: 12.7514 - acc: 0.4670\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 400us/step - loss: 12.7383 - acc: 0.4790\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s 414us/step - loss: 12.7248 - acc: 0.4680\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s 401us/step - loss: 12.7154 - acc: 0.4740\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 430us/step - loss: 12.7021 - acc: 0.4640\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 395us/step - loss: 12.6880 - acc: 0.4690\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 1s 651us/step - loss: 12.6744 - acc: 0.4470\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 1s 545us/step - loss: 12.6566 - acc: 0.4630\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 1s 581us/step - loss: 12.6428 - acc: 0.4600\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s 419us/step - loss: 12.6204 - acc: 0.4570\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 1s 624us/step - loss: 12.6037 - acc: 0.4650\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s 448us/step - loss: 12.5857 - acc: 0.4700\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 1s 516us/step - loss: 12.5654 - acc: 0.4640\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 1s 600us/step - loss: 12.5458 - acc: 0.4480\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 12.5256 - acc: 0.4560\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 1s 636us/step - loss: 12.5121 - acc: 0.4480\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 12.4966 - acc: 0.4490\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 1s 572us/step - loss: 12.4811 - acc: 0.4520\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 480us/step - loss: 12.4676 - acc: 0.4510\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 489us/step - loss: 12.4526 - acc: 0.4430\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 1s 558us/step - loss: 12.4420 - acc: 0.4380\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 12.4297 - acc: 0.4490\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 386us/step - loss: 12.4211 - acc: 0.4470\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 440us/step - loss: 12.4070 - acc: 0.4480\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 1s 561us/step - loss: 12.4023 - acc: 0.4510\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 1s 521us/step - loss: 12.3892 - acc: 0.4570\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 1s 597us/step - loss: 12.3835 - acc: 0.4490\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s 404us/step - loss: 12.3733 - acc: 0.4500\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s 332us/step - loss: 12.3635 - acc: 0.4610\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 1s 566us/step - loss: 12.3561 - acc: 0.4510\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 1s 581us/step - loss: 12.3474 - acc: 0.4690\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 1s 640us/step - loss: 12.3418 - acc: 0.4540\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 1s 547us/step - loss: 12.3332 - acc: 0.4670\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 1s 515us/step - loss: 12.3274 - acc: 0.4630\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 455us/step - loss: 12.3218 - acc: 0.4620\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 12.3112 - acc: 0.4670\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s 417us/step - loss: 12.3013 - acc: 0.4680\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 424us/step - loss: 12.2934 - acc: 0.4770\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s 453us/step - loss: 12.2872 - acc: 0.4820\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 12.2770 - acc: 0.4840\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s 469us/step - loss: 12.2698 - acc: 0.4860\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s 472us/step - loss: 12.2631 - acc: 0.4820\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 412us/step - loss: 12.2537 - acc: 0.4840\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s 400us/step - loss: 12.2450 - acc: 0.4920\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s 380us/step - loss: 12.2358 - acc: 0.4930\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 446us/step - loss: 12.2279 - acc: 0.5030\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s 423us/step - loss: 12.2183 - acc: 0.5110\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 436us/step - loss: 12.2144 - acc: 0.5010\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s 415us/step - loss: 12.2033 - acc: 0.5130\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 477us/step - loss: 12.1984 - acc: 0.5170\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s 424us/step - loss: 12.1842 - acc: 0.5120\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 480us/step - loss: 12.1787 - acc: 0.5240\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 428us/step - loss: 12.1693 - acc: 0.5380\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 496us/step - loss: 12.1562 - acc: 0.5410\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 440us/step - loss: 12.1556 - acc: 0.5290\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 487us/step - loss: 12.1418 - acc: 0.5330\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s 437us/step - loss: 12.1330 - acc: 0.5390\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 408us/step - loss: 12.1206 - acc: 0.5410\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s 426us/step - loss: 12.1131 - acc: 0.5610\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 438us/step - loss: 12.1036 - acc: 0.5330\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 425us/step - loss: 12.0943 - acc: 0.5590\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 424us/step - loss: 12.0829 - acc: 0.5510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f87531b7940>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "from keras.layers import Dense\n",
    "model.add(Dense(units=64, activation='relu', input_dim=24))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=12, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])\n",
    "# x_train and y_train are Numpy arrays --just like in the Scikit-Learn API.\n",
    "model.fit(train_x, train_y, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.11057403e-05   5.24028728e-05   2.57282764e-01   1.60208806e-01\n",
      "    2.00890303e-01   1.00930482e-01   7.24673271e-02   1.95794687e-01\n",
      "    1.77781180e-01   1.23060338e-01   2.05517784e-01   1.12059561e-03]\n",
      " [  5.15391439e-05   6.66522384e-01   1.68708637e-01   4.05870676e-01\n",
      "    2.85861224e-01   2.16168612e-01   2.70405352e-01   3.31489533e-01\n",
      "    3.61478448e-01   2.49370053e-01   2.00781509e-01   6.19518280e-01]\n",
      " [  9.76731098e-05   3.62819073e-08   2.96003986e-02   1.23332903e-01\n",
      "    5.76206148e-02   7.33633488e-02   7.84355327e-02   8.19563270e-02\n",
      "    1.02786712e-01   5.66309839e-02   8.53166655e-02   1.64780721e-01]\n",
      " [  1.64790559e-04   1.73524208e-02   3.50483626e-01   3.78051519e-01\n",
      "    2.43904293e-01   2.52667487e-01   2.55783260e-01   2.11421236e-01\n",
      "    3.67225111e-01   1.52992666e-01   2.59515941e-01   2.50328565e-03]\n",
      " [  3.72482500e-05   6.18487604e-07   4.12293412e-02   7.91352168e-02\n",
      "    9.14477333e-02   7.32327476e-02   1.08449861e-01   8.72623324e-02\n",
      "    1.41124010e-01   8.50275159e-02   2.59649903e-02   1.58655971e-01]\n",
      " [  1.09557550e-05   9.99442518e-01   2.37182498e-01   3.75170290e-01\n",
      "    2.59504825e-01   5.25293589e-01   4.40191954e-01   4.43357319e-01\n",
      "    5.84818363e-01   3.67148459e-01   1.67089477e-01   7.18163550e-01]\n",
      " [  4.46949503e-04   9.69999373e-01   1.82648748e-01   3.88057619e-01\n",
      "    3.93852860e-01   5.42675555e-01   4.04102385e-01   2.97263980e-01\n",
      "    4.05420303e-01   4.16171432e-01   2.04293400e-01   7.99771190e-01]\n",
      " [  1.22395781e-04   6.18286322e-06   1.62107468e-01   2.65312374e-01\n",
      "    1.09545112e-01   8.74678940e-02   9.90792662e-02   1.95099100e-01\n",
      "    2.35473871e-01   1.01400159e-01   1.22653462e-01   1.76763895e-03]\n",
      " [  1.21490296e-03   2.80466843e-02   4.20679659e-01   2.92308301e-01\n",
      "    2.86626101e-01   2.72763282e-01   2.34966964e-01   2.47074693e-01\n",
      "    3.24380547e-01   1.88058332e-01   1.88593507e-01   1.01081012e-02]\n",
      " [  9.13634722e-05   2.62731075e-04   2.35694900e-01   2.14740247e-01\n",
      "    1.11580953e-01   1.35139853e-01   1.03750981e-01   1.50056273e-01\n",
      "    1.56074032e-01   1.22565493e-01   7.10277706e-02   2.66873360e-01]]\n",
      "[[0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0], [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1], [0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0], [0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1], [0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1], [0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1], [0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0], [0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0], [0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(train_x)\n",
    "print(y_pred[0:10])\n",
    "print(train_y[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
